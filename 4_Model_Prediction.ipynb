{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53530f4c-22a3-40f4-a8a7-339e4bca4a7f",
   "metadata": {},
   "source": [
    "1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be499b65-91ee-41ba-ac83-e107e22908c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path.cwd().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Project modules\n",
    "from src.data.data_processing import DataProcessor\n",
    "from src.models.model_training import ModelTrainer\n",
    "\n",
    "# Load YAML configuration\n",
    "import yaml\n",
    "with open('configs/config.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Initialize data_processor (we will re-use it, but in is_prediction mode)\n",
    "data_processor = DataProcessor('configs/config.yml')\n",
    "\n",
    "# Initialize NLTK (quietly, so it won't re-download unnecessarily)\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] NLTK download failed: {e}\")\n",
    "\n",
    "print(\"[INFO] Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f68e7-b148-4684-8af5-f3f41bb4b4f5",
   "metadata": {},
   "source": [
    "2. Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf70dbc-f802-49a5-a359-8cc1eb3f8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load the Saved Model\n",
    "import joblib\n",
    "from src.models.model_factory import ModelFactory, LearningType\n",
    "\n",
    "def load_saved_model(model_path: str, vectorizer_path: str, config: Dict) -> ModelTrainer:\n",
    "    \"\"\"\n",
    "    Load a saved model (including training history and features).\n",
    "    \"\"\"\n",
    "    model_data = joblib.load(model_path)\n",
    "    print(\"[INFO] Loaded model_data keys:\", list(model_data.keys()))\n",
    "\n",
    "    # Create a ModelTrainer\n",
    "    trainer = ModelTrainer(config)\n",
    "\n",
    "    # Identify the learning type / model type from the saved object\n",
    "    model_type = model_data.get('model_type', 'classifier')\n",
    "    learning_type = model_data.get('learning_type', 'supervised')\n",
    "    print(f\"[INFO] Model type from file: {model_type}\")\n",
    "    print(f\"[INFO] Learning type from file: {learning_type}\")\n",
    "\n",
    "    # Construct a new model instance\n",
    "    if model_type == \"classifier\":\n",
    "        trainer.learning_type = LearningType.SUPERVISED_CLASSIFICATION\n",
    "        trainer.model = ModelFactory.create_model(LearningType.SUPERVISED_CLASSIFICATION, config)\n",
    "    elif model_type == \"regressor\":\n",
    "        trainer.learning_type = LearningType.SUPERVISED_REGRESSION\n",
    "        trainer.model = ModelFactory.create_model(LearningType.SUPERVISED_REGRESSION, config)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    # Load the actual sklearn estimator and info\n",
    "    trainer.model.model = model_data['model']\n",
    "    trainer.model.config = model_data['config']\n",
    "    trainer.model.training_history = model_data['training_history']\n",
    "    trainer.model.is_fitted = model_data['is_fitted']\n",
    "\n",
    "    # If you stored your training features inside 'model_data', load them:\n",
    "    if 'training_features' in model_data:\n",
    "        trainer.training_features = model_data['training_features']\n",
    "        print(f\"[INFO] Loaded {len(trainer.training_features)} training features.\")\n",
    "\n",
    "    # Load the fitted vectorizer\n",
    "    fitted_vectorizer = joblib.load(vectorizer_path)\n",
    "    print(\"[INFO] Loaded fitted vectorizer from:\", vectorizer_path)\n",
    "\n",
    "    # Now we can patch the DataProcessor with that fitted vectorizer\n",
    "    #    or create a brand new DataProcessor if needed.\n",
    "    #    For now let's assume we do this:\n",
    "    data_processor = DataProcessor('configs/config.yml')\n",
    "    data_processor.vectorizer = fitted_vectorizer\n",
    "    print(\"[INFO] DataProcessor is now holding the fitted vectorizer in .vectorizer\")\n",
    "\n",
    "    # Return both the trainer and the data_processor\n",
    "    return trainer, data_processor\n",
    "\n",
    "# Example usage of load_saved_model:\n",
    "MODEL_PATH = \"models/example_model/0.1.0/Deep Trees Model_20250116_172241_20250116_172241\"\n",
    "\n",
    "# # your saved vectorizer\n",
    "# (Adapt the file paths to however you saved them. If you saved them inside the same .pkl, you can directly load them from model_data['vectorizer'] as well.)\n",
    "VECTORIZER_PATH = \"models/tfidf_vectorizer.joblib\"\n",
    "\n",
    "try:\n",
    "    trainer, data_processor = load_saved_model(MODEL_PATH, VECTORIZER_PATH, config)\n",
    "    print(\"[INFO] Model loaded. Trainer learning_type =\", trainer.learning_type)\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] Model loading failed:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910ea3f-979e-411a-af33-21fffbbec568",
   "metadata": {},
   "source": [
    "3. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc7927-f879-4a42-9a51-f1453c39a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Predicting from a list of dictionaries\n",
    "def predict_sentiments(\n",
    "    data: List[Dict], \n",
    "    data_processor: DataProcessor, \n",
    "    trainer: ModelTrainer\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process incoming data payload and predict with the loaded model.\n",
    "    We do *not* rely on any CSV file. We build X from data payload.\n",
    "    \"\"\"\n",
    "    # 1) Convert the input payload into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 2) Process data in 'prediction' mode, so the vectorizer calls transform, not fit_transform\n",
    "    processed_df = data_processor.process_data(\n",
    "        df,\n",
    "        data_file_name='NO_SAVE.csv',\n",
    "        is_prediction=True\n",
    "    )\n",
    "\n",
    "    # 3) Identify the correct set of columns that the model expects\n",
    "    if hasattr(trainer, 'training_features') and trainer.training_features:\n",
    "        # Intersect with the columns we have\n",
    "        columns_we_have = processed_df.columns.tolist()\n",
    "        common_features = [col for col in trainer.training_features if col in columns_we_have]\n",
    "        if not common_features:\n",
    "            raise ValueError(\"No overlapping features between processed DF and trainer's training_features.\")\n",
    "\n",
    "        # Reorder processed_df to the same order\n",
    "        X = processed_df[common_features]\n",
    "    else:\n",
    "        # If no training_features are stored, use all numeric + encoded columns, or something else\n",
    "        X = processed_df\n",
    "\n",
    "    print(\"\\n[INFO] Using features for prediction:\", list(X.columns))\n",
    "\n",
    "    # 4) Predict\n",
    "    predictions = trainer.predict(X)\n",
    "\n",
    "    # 5) Attach predictions to each original item\n",
    "    results = []\n",
    "    for idx, row in enumerate(data):\n",
    "        row_copy = row.copy()\n",
    "        row_copy[\"predicted_sentiment\"] = predictions[idx]\n",
    "        results.append(row_copy)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84bb19-f127-4cef-ab0c-8ef7ae6f082d",
   "metadata": {},
   "source": [
    "4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccf85f-c4a5-4094-8dce-27168941bbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: Simulated Test Payload & Predictions\n",
    "\n",
    "# Example: Suppose user sends this data in an API call\n",
    "test_payload = [\n",
    "    {\n",
    "        \"tweet_id\": 123456789,\n",
    "        \"from_platform\": \"Nvidia\",\n",
    "        \"tweet\": \"NVIDIA still the big boss of hardware AI technologies\"\n",
    "    },\n",
    "    {\n",
    "        \"tweet_id\": 987654321,\n",
    "        \"from_platform\": \"Nvidia\",\n",
    "        \"tweet\": \"Fuck ! What's going wrong with this firm? They are producing a boring product\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Make predictions\n",
    "    prediction_results = predict_sentiments(test_payload, data_processor, trainer)\n",
    "\n",
    "    print(\"\\n[INFO] Prediction Results:\")\n",
    "    for item in prediction_results:\n",
    "        print(\"Tweet ID:\", item[\"tweet_id\"])\n",
    "        print(\"Platform:\", item[\"from_platform\"])\n",
    "        print(\"Tweet:\", item[\"tweet\"])\n",
    "        print(\"Predicted Sentiment:\", item[\"predicted_sentiment\"])\n",
    "        print(\"-\" * 70)\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] Prediction error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d90bf5-35df-4e78-89c2-8f2c909bb515",
   "metadata": {},
   "source": [
    "5. Utility Functions for Different Input Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21f1d7-e47f-440a-8d4b-4c3cea8b5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Additional Utilities\n",
    "\n",
    "def load_json_from_file(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Load incoming data from a JSON file.\"\"\"\n",
    "    import json\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def predict_from_json_file(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Predict from a JSON file directly.\"\"\"\n",
    "    data = load_json_from_file(file_path)\n",
    "    return predict_sentiments(data, data_processor, trainer)\n",
    "\n",
    "def predict_single_tweet(\n",
    "    tweet_text: str, \n",
    "    platform: str = \"Unknown\", \n",
    "    tweet_id: int = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Predict sentiment for a single tweet string.\n",
    "    \"\"\"\n",
    "    if tweet_id is None:\n",
    "        tweet_id = int(time.time())  # Random ID\n",
    "    single_payload = [{\n",
    "        \"tweet_id\": tweet_id,\n",
    "        \"from_platform\": platform,\n",
    "        \"tweet\": tweet_text\n",
    "    }]\n",
    "    results = predict_sentiments(single_payload, data_processor, trainer)\n",
    "    return results[0]\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    single_tweet_text = \"I love the new GPU performance from Nvidia!\"\n",
    "    single_pred = predict_single_tweet(single_tweet_text, \"Twitter\")\n",
    "    print(\"\\nSingle tweet prediction ->\", single_pred)\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] Single tweet prediction error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec2d04-e548-4450-a76f-008fe68fa3fa",
   "metadata": {},
   "source": [
    "6. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e33e7-0c57-45d8-8b21-01f905f77ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Example Usage\n",
    "try:\n",
    "    # 1. Predict from JSON string\n",
    "    json_str = '''\n",
    "    [\n",
    "        {\n",
    "            \"tweet_id\": 123456789,\n",
    "            \"from_platform\": \"Nvidia\",\n",
    "            \"tweet\": \"NVIDIA still the big boss of hardware AI technologies\"\n",
    "        },\n",
    "        {\n",
    "            \"tweet_id\": 987654321,\n",
    "            \"from_platform\": \"Nvidia\",\n",
    "            \"tweet\": \"What's going wrong with this firm. They are producing a bullshit\"\n",
    "        }\n",
    "    ]\n",
    "    '''\n",
    "    test_data = json.loads(json_str)\n",
    "    #results = predict_sentiments(test_data, data_processor, trainer)\n",
    "\n",
    "    # 2. Predict single tweet\n",
    "    #single_result = predict_single_tweet(\n",
    "        \"NVIDIA's new GPU is amazing!\",\n",
    "        platform=\"Twitter\"\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nSingle Tweet Prediction:\")\n",
    "    print(f\"Tweet: {single_result['tweet']}\")\n",
    "    print(f\"Predicted Sentiment: {single_result['predicted_sentiment']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Example usage error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
